{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9hTNr6Nq0tr",
        "outputId": "57e8e6fd-661d-4acd-fe39-16218bc636bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Install required libraries\n",
        "!pip install transformers datasets sentencepiece scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Import libraries\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "CYd74ySRzrO-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Prepare your dataset\n",
        "# Example: 50 old sentences + modern equivalents\n",
        "old_sentences = [\n",
        "    \"Bir çox sifətlər var insanda hələ\",\n",
        "\"Almasan yaxşıdır onları dilə\",\n",
        "\"Pis sözü ağzına alınca insan\",\n",
        "\"Qarnında öldürsə yaxşıdır, inan\",\n",
        "\"Bu dünya dolanıb döndükcə ruzgar\",\n",
        "\"Qoy səndən yaxşı söz qalsın yadigar\",\n",
        "\n",
        "    \"Harda ki eşq əli bir süfrə açar\",\n",
        "\"Bu gözəl hekayə ona duz saçar\",\n",
        "\"Bu qədər nazəndə, incə bir dilbər\",\n",
        "\"Nədən çılpaq qalsın bu vaxta qədər\",\n",
        "\"Onu bəzəməmiş arif əlləri\",\n",
        "\"Odur ki, çılpaqdır o gözəl pəri\",\n",
        "\n",
        "\"Daim xaraba da olsa bir diyar\",\n",
        "\"Bil ki, abadlıqdan onda nişan var\",\n",
        "\"İstər xarab olsun, istərsə abad\",\n",
        "\"Daimi bünövrə qoymamış həyat\",\n",
        "\n",
        "\"Ey varlıq nəqşinin naziri olan\",\n",
        "\"Qaldır əngəlləri idrak yolundan\",\n",
        "\"Boş təbli döyərək hay-haray salma\",\n",
        "\"Heç kəsin səsinə biganə qalma\",\n",
        "\"Bir toz görünsə də hər zərrə əgər\",\n",
        "\"Dünya pərdəsində o da iş görər\",\n",
        "\n",
        "    \"Qısa söz; dünyada nə sən, nə də mən\",\n",
        "\"Oyuncaq deyilik xilqətimizdən\",\n",
        "\"Nə şəhvət, nə yuxu, nə də ki yemek\",\n",
        "\"Həyatın mənası olmasın gərək\",\n",
        "\"Yatmağı, yeməyi bu aləmdə sən\",\n",
        "\"Eşşək, öküzdə də görə bilərsən\",\n",
        "\"Təbiət quranda xilqətimizi\",\n",
        "\"Başqa səhifədə yazmışdır bizi\",\n",
        "\n",
        "    \"İlahi, dar gündə sən ol həmdəmim\",\n",
        "    \"İstədiyin yerə çatsın qədəmim\",\n",
        "\"Söylə nə vaxtadək bir tikə üçün\" ,\n",
        "    \"Şaha və gədaya yalvarım hər gün\",\n",
        "\n",
        "    \"Məcnun bəslədikcə o heyvanları\",\n",
        "\"Çəkdi dövrəsinə bir can hasarı\",\n",
        "\"Hasar ətrafında gəzən hər heyvan\",\n",
        "\"Məcnunun işinə yaradı hər an\",\n",
        "\"Məcnuna bənzəsən insanlıqda sən\",\n",
        "\"Dünyada nə qüssə, nə qəm çəkərsən\",\n",
        "\n",
        "    \"Ata öz oğlunu əzizləyən tək\",\n",
        "\"Məcnun da maralı əzizləyərək\",\n",
        "\"Tutub sığalladı o dildarını\",\n",
        "\"Məni pis taleyim təqib edir, bil\",\n",
        "\"Heç kəs bədbəxtlikdən qurtaran deyil\",\n",
        "\"Sən də mi yarından düşdün aralı\",\n",
        "\"Ey çöl qoşununun gözəl sarbanı\",\n",
        "\"Dağlar döşündəki çadırın hanı\",\n",
        "\"Xoş ətrin canandan gətirir xəbər\",\n",
        "\"Gözün sevgilimin gözünə bənzər\",\n",
        "\n",
        "\n",
        "]\n",
        "modern_sentences = [\n",
        "    \"İnsanda hələ çox sifətlər var\",\n",
        "    \"Onları dilə gətirməsən yaxşıdır\",\n",
        "    \"İnsan pis söz demək istəyəndə\",\n",
        "    \"Qarnında boğub saxlaması daha yaxşıdır\",\n",
        "    \"Dünya fırlanıb dolandıqca ruzgar\",\n",
        "    \"Qoy səndən xoş söz yadigar qalsın\",\n",
        "\n",
        "    \"Harada ki eşq süfrə açır\",\n",
        "    \"Gözəl bir hekayə ona dad qatır\",\n",
        "    \"Bu qədər nazlı, incə bir gözəl\",\n",
        "    \"Niyə indiyə qədər bəzəksiz qalsın\",\n",
        "    \"Onu arif əllər bəzəməyib\",\n",
        "    \"Ona görə də çılpaqdır o gözəl pəri\",\n",
        "\n",
        "    \"Bir diyar daim xaraba görünsə də\",\n",
        "    \"Bil ki, onda abadlığın izi var\",\n",
        "    \"İstər xaraba olsun, istər abad\",\n",
        "    \"Həyat heç vaxt daimi bünövrə qoymayıb\",\n",
        "\n",
        "    \"Ey varlığın gözəlliyini qoruyan\",\n",
        "    \"Qaldır maneələri idrak yolundan\",\n",
        "    \"Boş təbil çalıb hay-küy salma\",\n",
        "    \"Heç kimin səsinə laqeyd qalma\",\n",
        "    \"Bir zərrə toz görünsə belə\",\n",
        "    \"Dünya səhnəsində onun da rolu var\",\n",
        "\n",
        "    \"Qısaca desək: nə sən, nə də mən\",\n",
        "    \"Xilqətimizdən oyuncaqlar deyilik\",\n",
        "    \"Nə şəhvət, nə yuxu, nə də yemək\",\n",
        "    \"Həyatın mənası olmamalıdır\",\n",
        "    \"Yatmaqla, yeməklə bu dünyada\",\n",
        "    \"Eşşəkdə, öküzdə də rastlaşa bilərsən\",\n",
        "    \"Təbiət yaradanda xilqətimizi\",\n",
        "    \"Bizim üçün ayrıca səhifə yazıb\",\n",
        "\n",
        "    \"İlahi, çətin gündə sən mənim həmdəmim ol\",\n",
        "    \"Addımlarım istədiyin yerə çatsın\",\n",
        "    \"De görüm, nə vaxta qədər bir tikə çörək üçün\",\n",
        "    \"Hər gün həm şahdan, həm də kasıbdan dilənim\",\n",
        "\n",
        "    \"Məcnun heyvanları bəslədikcə\",\n",
        "    \"Onların ətrafında bir canlı hasar qurdu\",\n",
        "    \"Hasarın ətrafında gəzən hər heyvan\",\n",
        "    \"Məcnunun işinə hər an yaradı\",\n",
        "    \"Əgər sən də insanlıqda Məcnuna bənzəsən\",\n",
        "    \"Dünyada nə qüssə, nə də kədər çəkərsən\",\n",
        "\n",
        "    \"Ata öz oğlunu necə əzizləyirsə\",\n",
        "    \"Məcnun da maralı sevərək sığallayırdı\",\n",
        "    \"O, sevimlisini tutub oxşayırdı\",\n",
        "    \"Amma məni pis tale izləyir, bil\",\n",
        "    \"Heç kəs bədbəxtlikdən qurtula bilmir\",\n",
        "    \"Sən dəmi sevgilindən ayrı düşmüsən\",\n",
        "    \"Ey səhrada karvanı aparan gözəl sarban\",\n",
        "    \"Dağların döşündəki çadırın hanı\",\n",
        "    \"Xoş ətrin sevgilidən xəbər gətirir\",\n",
        "    \"Gözlərin sevgilimin gözlərinə bənzəyir\"\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "KLe0xEhbzuWT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Load sentiment analysis models\n",
        "xlmr_model = pipeline(\"sentiment-analysis\", model=\"xlm-roberta-base\")\n",
        "bert_model = pipeline(\"sentiment-analysis\", model=\"bert-base-multilingual-cased\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPPXM-aez9O5",
        "outputId": "93f6ab42-9f29-496f-c030-3c9ec526cdaa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Device set to use cpu\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Run sentiment analysis\n",
        "xlmr_results = [xlmr_model(s)[0] for s in modern_sentences]\n",
        "bert_results = [bert_model(s)[0] for s in modern_sentences]\n",
        "\n",
        "print(\"XLM-R Sentiment Results:\", xlmr_results[:5])\n",
        "print(\"BERT Sentiment Results:\", bert_results[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfHIFE8r0Cit",
        "outputId": "ea3c642c-7efd-48e9-816d-0df3ca671bee"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XLM-R Sentiment Results: [{'label': 'LABEL_1', 'score': 0.5271710157394409}, {'label': 'LABEL_1', 'score': 0.5242962837219238}, {'label': 'LABEL_1', 'score': 0.5247834324836731}, {'label': 'LABEL_1', 'score': 0.5274254679679871}, {'label': 'LABEL_1', 'score': 0.5271636843681335}]\n",
            "BERT Sentiment Results: [{'label': 'LABEL_0', 'score': 0.5282865166664124}, {'label': 'LABEL_0', 'score': 0.5259682536125183}, {'label': 'LABEL_0', 'score': 0.5024901032447815}, {'label': 'LABEL_0', 'score': 0.532522439956665}, {'label': 'LABEL_0', 'score': 0.5314029455184937}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Convert labels to numeric for metrics\n",
        "def label_to_num(label):\n",
        "    return 1 if label.lower() in [\"positive\"] else 0\n",
        "\n",
        "y_true = [\n",
        " 1,1,0,0,1,1,\n",
        " 1,1,1,0,0,0,\n",
        " 0,1,0,0,\n",
        " 1,1,0,1,1,1,\n",
        " 0,0,0,0,0,0,1,1,\n",
        " 0,1,0,0,\n",
        " 1,1,1,1,1,1,\n",
        " 1,1,1,0,0,0,1,0,1,1\n",
        "]\n",
        "\n",
        "\n",
        "y_pred_xlmr = [label_to_num(r['label']) for r in xlmr_results]\n",
        "y_pred_bert = [label_to_num(r['label']) for r in bert_results]"
      ],
      "metadata": {
        "id": "ZTj0lNc40MDu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Calculate metrics\n",
        "print(\"XLM-R Metrics:\")\n",
        "print(\"Precision:\", precision_score(y_true, y_pred_xlmr))\n",
        "print(\"Recall:\", recall_score(y_true, y_pred_xlmr))\n",
        "print(\"F1:\", f1_score(y_true, y_pred_xlmr))\n",
        "\n",
        "print(\"BERT Metrics:\")\n",
        "print(\"Precision:\", precision_score(y_true, y_pred_bert))\n",
        "print(\"Recall:\", recall_score(y_true, y_pred_bert))\n",
        "print(\"F1:\", f1_score(y_true, y_pred_bert))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J12adp742ol3",
        "outputId": "a8315548-bd6f-47ca-fecc-b58c1b920c9b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XLM-R Metrics:\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1: 0.0\n",
            "BERT Metrics:\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 8: Sentence similarity\n",
        "# Use embeddings from XLM-R\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"xlm-roberta-base\")\n",
        "\n",
        "def get_embedding(sentence):\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "    return outputs.logits.detach().numpy()\n",
        "\n",
        "embeddings = [get_embedding(s) for s in modern_sentences]\n",
        "similarity_matrix = cosine_similarity(np.vstack(embeddings))\n",
        "\n",
        "print(\"Similarity Matrix Shape:\", similarity_matrix.shape)\n",
        "print(\"Similarity between sentence 1 and 2:\", similarity_matrix[0][1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wHnFPMC6hGe",
        "outputId": "31010974-f908-4af8-b9ba-4b84259c25a1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity Matrix Shape: (50, 50)\n",
            "Similarity between sentence 1 and 2: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Sentence similarity between old and modern sentences\n",
        "from transformers import AutoModel\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Use XLM-R base model for embeddings\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
        "model = AutoModel.from_pretrained(\"xlm-roberta-base\")\n",
        "\n",
        "def get_embedding(sentence):\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    # Mean pooling of last hidden state\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Get embeddings for old and modern sentences\n",
        "old_embeddings = [get_embedding(s) for s in old_sentences]\n",
        "modern_embeddings = [get_embedding(s) for s in modern_sentences]\n",
        "\n",
        "# Compare each old sentence with its modern equivalent\n",
        "for i in range(len(old_sentences)):\n",
        "    sim = cosine_similarity(old_embeddings[i], modern_embeddings[i])[0][0]\n",
        "    print(f\"Similarity between old and modern sentence {i+1}: {sim:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "np9hCRji60Va",
        "outputId": "10fd5a6c-279a-415e-8eb3-44a7c056726c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between old and modern sentence 1: 0.9995\n",
            "Similarity between old and modern sentence 2: 0.9975\n",
            "Similarity between old and modern sentence 3: 0.9962\n",
            "Similarity between old and modern sentence 4: 0.9984\n",
            "Similarity between old and modern sentence 5: 0.9957\n",
            "Similarity between old and modern sentence 6: 0.9997\n",
            "Similarity between old and modern sentence 7: 0.9972\n",
            "Similarity between old and modern sentence 8: 0.9976\n",
            "Similarity between old and modern sentence 9: 0.9991\n",
            "Similarity between old and modern sentence 10: 0.9977\n",
            "Similarity between old and modern sentence 11: 0.9989\n",
            "Similarity between old and modern sentence 12: 0.9990\n",
            "Similarity between old and modern sentence 13: 0.9963\n",
            "Similarity between old and modern sentence 14: 0.9983\n",
            "Similarity between old and modern sentence 15: 0.9991\n",
            "Similarity between old and modern sentence 16: 0.9989\n",
            "Similarity between old and modern sentence 17: 0.9969\n",
            "Similarity between old and modern sentence 18: 0.9987\n",
            "Similarity between old and modern sentence 19: 0.9985\n",
            "Similarity between old and modern sentence 20: 0.9989\n",
            "Similarity between old and modern sentence 21: 0.9989\n",
            "Similarity between old and modern sentence 22: 0.9982\n",
            "Similarity between old and modern sentence 23: 0.9987\n",
            "Similarity between old and modern sentence 24: 0.9988\n",
            "Similarity between old and modern sentence 25: 0.9994\n",
            "Similarity between old and modern sentence 26: 0.9974\n",
            "Similarity between old and modern sentence 27: 0.9970\n",
            "Similarity between old and modern sentence 28: 0.9995\n",
            "Similarity between old and modern sentence 29: 0.9989\n",
            "Similarity between old and modern sentence 30: 0.9978\n",
            "Similarity between old and modern sentence 31: 0.9994\n",
            "Similarity between old and modern sentence 32: 0.9966\n",
            "Similarity between old and modern sentence 33: 0.9983\n",
            "Similarity between old and modern sentence 34: 0.9951\n",
            "Similarity between old and modern sentence 35: 0.9997\n",
            "Similarity between old and modern sentence 36: 0.9974\n",
            "Similarity between old and modern sentence 37: 0.9990\n",
            "Similarity between old and modern sentence 38: 0.9985\n",
            "Similarity between old and modern sentence 39: 0.9981\n",
            "Similarity between old and modern sentence 40: 0.9994\n",
            "Similarity between old and modern sentence 41: 0.9985\n",
            "Similarity between old and modern sentence 42: 0.9971\n",
            "Similarity between old and modern sentence 43: 0.9964\n",
            "Similarity between old and modern sentence 44: 0.9980\n",
            "Similarity between old and modern sentence 45: 0.9994\n",
            "Similarity between old and modern sentence 46: 0.9982\n",
            "Similarity between old and modern sentence 47: 0.9974\n",
            "Similarity between old and modern sentence 48: 0.9998\n",
            "Similarity between old and modern sentence 49: 0.9987\n",
            "Similarity between old and modern sentence 50: 0.9987\n"
          ]
        }
      ]
    }
  ]
}